#!/usr/bin/env python2
from __future__ import print_function
import argparse
import os
import sys
import subprocess
import math
import configparser
import zmq
import threading
import select
import logging
import logging.handlers

import terranet
import terranet.config

import multiprocessing
import functools
import progress.bar
import time

import json
import itertools
import jinja2

from terranet.komondor import Komondor


class PseudoMeterer(threading.Thread):
    def __init__(self, src, dst, socket, zmq_lock):
        super(PseudoMeterer, self).__init__()
        self.running = False
        self.dst = dst
        self.src = src
        self.socket = socket
        self.zmq_lock = zmq_lock

    def run(self):
        self.running = True
        log = logging.getLogger(__name__)
        log.debug('Entering Iperf thread for client {}.'.format(self.dst.name))

        topic = 'flows/{}'.format(self.dst.name)
        p = None
        ip6 = None
        while ip6 is None:
            _, ip6 = terranet.address_pair(self.dst)
            if ip6 is None:
                log.debug('Waiting for IPv6 address of client {}'.format(self.dst.name))
                time.sleep(3)
                continue

        while self.running:

            duration = 3000  # Make it very long to have stable flows.
            cmd = 'iperf -y c -V -t {} -i 5 -c {}'.format(duration, ip6)

            log.debug('Starting iperf for client {} with: {}'.format(self.dst.name, cmd))
            p = self.src.popen(cmd)
            log.info('Started iperf process for client {} ({}).'.format(self.dst.name, ip6))

            while self.running:
                rlist, _, _ = select.select([p.stdout, p.stderr], [], [], 7)

                if not rlist:
                    log.warning('Iperf process for client {} timed out.'.format(self.dst.name))
                    continue

                if p.stderr in rlist:
                    err = p.stderr.readline()

                    if err != "":
                        err_out = p.stderr.readline()
                        log.warn('Iperf for client {} encountered an error: {} '.format(self.dst.name, err_out))

                if p.poll() is not None:
                    log.warn('Iperf process for client {} exited unexpectedly.'.format(self.dst.name))
                    time.sleep(3)
                    break

                if p.stdout in rlist:
                    o = p.stdout.readline()

                    if o == "":
                        break

                    payload = "{}".format(int(o.split(',')[8]) / 1e6)
                    time_span = float(o.split(',')[6].split('-')[1]) - float(o.split(',')[6].split('-')[0])

                    if time_span > duration:
                        continue  # Skip summary line

                    log.debug('Payload for client {}({}): {}'.format(self.dst.name, ip6, payload))

                    with self.zmq_lock:
                        try:
                            # NOBLOCK necessary to prevent deadlock
                            self.socket.send(topic, flags=zmq.SNDMORE | zmq.NOBLOCK)
                            self.socket.send(payload, flags=zmq.NOBLOCK)
                        except zmq.ZMQError:
                            log.error('Dropping message due to full queue')

            log.info('Iperf process for client {} ({}) exited.'.format(self.dst.name, ip6))

        if p and p.poll() is None:
            log.info('Stopping iperf process with pid {}'.format(p.pid))
            p.kill()


class FronthaulEmulatorSwitch(threading.Thread):
    def __init__(self, hostname, sub_port, fh_emulator, default, best):
        super(FronthaulEmulatorSwitch, self).__init__()
        self.sub_port = sub_port
        self.hostname = hostname
        self.running = False
        self.fh_emulator = fh_emulator
        self.default = default
        self.best = best

    def run(self):
        self.running = True
        ctx = zmq.Context()
        sub = ctx.socket(zmq.SUB)
        sub.setsockopt(zmq.SUBSCRIBE, 'controller')
        sub.connect('tcp://{}:{}'.format(self.hostname, self.sub_port))

        while self.running:
            rlist, _, _ = zmq.select([sub], [], [], 3.0)
            if sub in rlist:
                topic, content = sub.recv_multipart()
                with self.fh_emulator.lock:
                    index = self.best if content == 'true' else self.default
                    self.fh_emulator.current_tuple = self.fh_emulator.cfg_tuples[index]
                    self.fh_emulator.apply_global_config(self.fh_emulator.current_tuple)

        sub.close()


def config_metric(cfg_tuple, network):
    p = configparser.ConfigParser()
    log = logging.getLogger(__name__)
    with open(cfg_tuple[1], 'r') as f:
        p.read_file(f)

    metric = 0.0
    for sta in filter(lambda s: s.startswith('Node_'), p.sections()):
        name = sta.split('Node_')[1]
        tp = p.getfloat(sta, 'throughput')
        wlan = p.get(sta, 'wlan')

        clients = None
        for n in network['networks']:
            if n['wlan_code'] != wlan:
                continue
            sta_index = int(name.split('STA_{}'.format(wlan))[1]) - 1
            clients = n['stas'][sta_index]['clients']

        if clients is None:
            log.debug('No client number specified for {}. Defaulting to 1.'.format(name))
            clients = 1

        try:
            metric += math.log(tp / clients) * clients if clients > 0 else 0
        except ValueError as e:
            log.debug('{} for {}->tp = {} in {}'.format(e, name, tp, cfg_tuple[1]))

    return metric


def config_parse_proxy(file):
    return terranet.config.Config.from_file(file)  # This is necessary to allow pickling for pool.map()


def run(args):
    log = logging.getLogger(__name__)

    pool = multiprocessing.Pool()
    join_cfg_paths = functools.partial(os.path.join, args.cfg_path)
    cfg_files = pool.map(join_cfg_paths,
                         filter(lambda p: p.endswith('.cfg') and os.path.isfile(os.path.join(args.cfg_path, p)),
                                os.listdir(args.cfg_path)))
    cfg_files.sort()

    if len(cfg_files) < 1:
        log.error('No configuration files found. Exiting...')
        pool.close()
        sys.exit(-1)

    join_out_paths = functools.partial(os.path.join, args.out_path)
    out_files = pool.map(join_out_paths,
                         filter(lambda p: p.endswith('.cfg') and os.path.isfile(os.path.join(args.out_path, p)),
                                os.listdir(args.cfg_path)))  # Use the same files names to get corresponding outputs
    out_files.sort()

    if len(out_files) != len(cfg_files):
        log.error('Missing simulation results for given configurations!')
        pool.close()
        sys.exit(-1)

    log.info('Found {} configurations and corresponding simulation results.'.format(len(cfg_files)))
    log.info('Parsing...')
    tn_configs = pool.map(config_parse_proxy, cfg_files)
    cfg_tuples = zip(tn_configs, out_files)
    pool.close()

    log.info('Searching results for default configuration...')
    default = list(filter(lambda cfg_tup: False not in
                                          map(lambda ap: int(ap.max_channel_allowed) - int(ap.min_channel_allowed) == 7,
                                              cfg_tup[0].get_access_points()),
                          cfg_tuples))[0]

    limiter = terranet.FronthaulEmulator(cfg_tuples, args.config_port, starting_index=cfg_tuples.index(default))
    log.info('Generating ipmininet topology...')

    with open(args.network) as f:
        network_json = json.load(f)

    topo = terranet.TerraNetTopo.from_network_dict(network_json, limiter)
    net = terranet.TerraNet(topo=topo)

    log.info('Starting ipmininet...')
    net.start()

    key = functools.partial(config_metric, network=network_json)
    best = sorted(cfg_tuples, key=key, reverse=True)[0]

    # Should be built before drawing
    # terranet.draw_network(net, '/tmp/topology.png')
    net.draw('/tmp/topology.png')
    topo_server = subprocess.Popen(['python2', '-m', 'SimpleHTTPServer', '{}'.format(args.topo_port)],
                                   cwd='/tmp/',
                                   stdout=open(os.devnull, 'w'), stderr=open(os.devnull, 'w'),
                                   close_fds=True)

    iperf_threads = []
    gw = net['gw']

    zmq_lock = threading.Lock()
    ctx = zmq.Context()
    s = ctx.socket(zmq.PUB)
    s.bind('tcp://127.0.0.1:{}'.format(args.metering_port))

    for client in filter(lambda h: isinstance(h, terranet.TerraNetClient), net.hosts):
        p = PseudoMeterer(gw, client, s, zmq_lock)
        iperf_threads.append(p)
        p.start()

    flipswitch = FronthaulEmulatorSwitch('localhost', 4567, limiter, cfg_tuples.index(default), cfg_tuples.index(best))
    flipswitch.start()

    try:
        terranet.IPCLI(net)
    except:
        log.exception('Exception in IPCLI')
    finally:
        log.info('Stopping...')

        log.info('Terminating Web server...')
        topo_server.terminate()
        log.info('Terminated Web server.')

        log.info('Stopping Iperf client processes...')

        for t in iperf_threads:
            t.running = False

        for t in iperf_threads:
            t.join()

        log.info('Stopping flipswitch...')

        flipswitch.running = False
        flipswitch.join()
        s.close()

        log.info('Stopping mininet...')
        net.stop()
        log.info('Mininet stopped.')


def channel_combinations():
    return list(filter(lambda t: t[1] - t[0] in [0, 1, 3, 7],
                       itertools.product(range(8), repeat=2)))


def get_template(*args, **kwargs):
    env = jinja2.Environment(
        loader=jinja2.PackageLoader('terranet', 'templates'),
    )
    template = env.get_template('config.j2')
    return template.render(*args, **kwargs)


def generate_config(networks, channels):
    system = terranet.config.System()
    nodes = []

    for ap_idx, net in enumerate(networks):
        wlan_code = net["wlan_code"]
        name = "Node_AP_{}".format(wlan_code)
        (min_ch, max_ch) = channels[ap_idx]

        args = {"wlan_code": wlan_code,
                "primary_channel": min_ch,
                "min_channel_allowed": min_ch,
                "max_channel_allowed": max_ch,
                "x": net["ap"]["x"],
                "y": net["ap"]["y"],
                "z": net["ap"]["z"]
                }

        ap = terranet.config.AccessPoint(name=name, **args)
        nodes.append(ap)

        num_stas = len(net["stas"])
        for sta_idx, sta in enumerate(range(num_stas)):
            name = "Node_STA_{}{}".format(wlan_code, sta_idx + 1)
            args = {"wlan_code": wlan_code,
                    "primary_channel": min_ch,
                    "min_channel_allowed": min_ch,
                    "max_channel_allowed": max_ch,
                    "x": net["stas"][sta_idx]["x"],
                    "y": net["stas"][sta_idx]["y"],
                    "z": net["stas"][sta_idx]["z"]
                    }
            sta = terranet.config.Station(name=name, **args)
            nodes.append(sta)

    return terranet.config.Config(system=system, nodes=nodes)


def generator_worker((iteration, channels), network, max_digits):
        config = generate_config(network["networks"], channels)
        template = get_template(config=config)
        suffix = format(iteration, "0{}".format(max_digits))
        file_name = os.path.join(args.cfg_dir, 'terranet_{}.cfg'.format(suffix))
        with open(file_name, "w") as f:
            f.write(template)


def generate(args):
    log = logging.getLogger(__name__)

    try:
        with open(args.topology, 'r') as f:
            network = json.load(f)
    except OSError as e:
        log.exception('Unable to open network description!')

    ap_combinations = list(itertools.product(channel_combinations(),
                                             repeat=len(network["networks"])))

    max_digits = int(math.log10(len(ap_combinations))) + 1

    pool = multiprocessing.Pool()
    worker_func = functools.partial(generator_worker, network=network, max_digits=max_digits)
    pool.map(worker_func, enumerate(ap_combinations))
    pool.close()

    log.info('Generated {} configurations.'.format(len(ap_combinations)))


def init(q):
    global queue
    queue = q


def simulate(args):
    log = logging.getLogger(__name__)
    if not os.path.isdir(args.cfg_dir):
        log.error("--cfg_dir must be a valid directory.")
        return -1

    if not os.path.isdir(args.out_dir):
        log.error("--out_dir must be a valid directory.")
        return -1

    dirs = {"cfg": args.cfg_dir, "out": args.out_dir}
    komondor_args = {"time": args.time, "seed": args.seed}

    cfg_files = list(filter(
        lambda x: x.endswith(".cfg"),
        os.listdir(dirs["cfg"])
    ))

    log.info('Found {} configurations to simulate.'.format(len(cfg_files)))
    q = multiprocessing.Queue()
    bar = progress.bar.Bar('Simulating combinations', max=len(cfg_files))
    pool = multiprocessing.Pool(args.processes, initializer=init, initargs=(q,))
    f = functools.partial(komondor_worker, dirs=dirs, komondor=args.komondor,
                          komondor_args=komondor_args)
    t1 = time.time()
    async_res = pool.map_async(f, cfg_files)

    while not async_res.ready():
        try:
            q.get(timeout=5.0)
            bar.next()
        except Exception as e:
            # Race condition
            # async might not be ready yet
            # but queue is already empty
            pass

    while not q.empty():
        try:
            q.get(False)
            bar.next()
        except:
            log.debug('Timeout while waiting.')

    try:
        async_res.get()  # Get result to trigger possible exceptions
    except RuntimeError as e:
        print(e)

    t2 = time.time()
    pool.close()
    bar.finish()
    log.info('Completed {} simulations in {} seconds.'.format(len(cfg_files), t2 - t1))


def komondor_worker(cfg, dirs, komondor=None, komondor_args=None):
    global queue
    cfg_file = os.path.abspath(os.path.join(dirs["cfg"], cfg))
    result_file = os.path.abspath(os.path.join(dirs["out"], cfg))
    args = komondor_args.copy()
    args["stats"] = result_file
    k = Komondor(executable=komondor)

    (proc, stdout, stderr) = k.run(cfg_file, **args)
    queue.put(stderr + stdout)

    return stderr


def init_logging():

    root = logging.getLogger()
    root.setLevel(logging.DEBUG)

    format = logging.Formatter()

    s = logging.StreamHandler()
    s.setLevel(logging.INFO)
    s.setFormatter(format)

    f = logging.handlers.RotatingFileHandler('/tmp/terranet.log', maxBytes=1024**2, backupCount=1)
    f.setLevel(logging.DEBUG)
    f.setFormatter(format)

    root.addHandler(s)
    root.addHandler(f)


if __name__ == '__main__':
    init_logging()
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    gen_parser = subparsers.add_parser('generate',
                                       help='Generate a permutation of possible Komondor configurations based on simple topology.')
    gen_parser.set_defaults(func=generate)

    gen_parser.add_argument('topology', type=str, help='JSON file containing the basic network topology.')
    gen_parser.add_argument('--cfg_dir', default='cfg', type=str,
                            help='Output directory for generated configurations. Defaults to "cfg".')

    simulate_parser = subparsers.add_parser('simulate', help='start Komondor simulator with generated configurations')
    simulate_parser.set_defaults(func=simulate)
    simulate_parser.add_argument('--cfg_dir',
                                 nargs='?',
                                 default="cfg",
                                 type=str,
                                 help='Input directory of generated configurations. Defaults to "cfg".')
    simulate_parser.add_argument('--out_dir',
                                 nargs='?',
                                 default="out",
                                 type=str,
                                 help='Output directory for simulation results. Defaults to "out".')
    simulate_parser.add_argument('--time',
                                 nargs='?',
                                 default=100,
                                 type=int,
                                 help="Simulation duration in seconds. Defaults to 100 seconds.")
    simulate_parser.add_argument('--seed',
                                 nargs='?',
                                 default=1000,
                                 type=int,
                                 help='')
    simulate_parser.add_argument('--processes',
                                 nargs='?',
                                 default=None,
                                 type=int,
                                 help='Number of parallel running simulations. Defaults to os.cpu_count().')
    simulate_parser.add_argument('--komondor',
                                 nargs='?',
                                 type=str,
                                 default='komondor',
                                 help='Path to Komondor executable. Defaults to "komondor".')

    run_parser = subparsers.add_parser('run', help='Run emulated Terranet in Mininet.')
    run_parser.set_defaults(func=run)
    run_parser.add_argument('network', help='Path to JSON file describing the network')
    run_parser.add_argument('cfg_path', help='Path to configuration files for komondor simulation')
    run_parser.add_argument('out_path', help='Path to the simulation results')
    run_parser.add_argument('-t', '--topo-port',
                            help='Set port of web server serving the topology image. Defaults to 6666.',
                            type=int,
                            default=6666)
    run_parser.add_argument('-m', '--metering-port',
                            help='Set port for publishing flow metering info. Defaults to 5556.',
                            type=int,
                            default=5556)
    run_parser.add_argument('-c', '--config-port',
                            help='Set port for publishing configuration changes. Defaults to 4568.',
                            type=int,
                            default=4568)

    args = parser.parse_args()
    args.func(args)
